{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaimevt88/DL012020/blob/master/U4.proyect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t50J3nYwq5Sp",
        "colab_type": "code",
        "outputId": "61623a2a-dd74-45df-ec15-ed372d80df45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=18cyWOHXhenkCD1Fiyct-_7pZXRfnK2Yv' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=18cyWOHXhenkCD1Fiyct-_7pZXRfnK2Yv\" -O data2D.zip && rm -rf /tmp/cookies.txt\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1q_NULDeoIHmZTPeMCiGMFOnxP5v0o4vf' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1q_NULDeoIHmZTPeMCiGMFOnxP5v0o4vf\" -O data1D.zip && rm -rf /tmp/cookies.txt\n",
        "!unzip data2D.zip\n",
        "!unzip data1D.zip\n",
        "!rm -rf data*.zip\n",
        "!mkdir 1D\n",
        "!mkdir 2D"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-03 03:44:56--  https://docs.google.com/uc?export=download&confirm=HvPs&id=18cyWOHXhenkCD1Fiyct-_7pZXRfnK2Yv\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.203.113, 74.125.203.100, 74.125.203.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.203.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-4k-docs.googleusercontent.com/docs/securesc/2d2i9c4pjd8noh2kmtrrgddb5s319ckl/s3t06c5kusr0pq0ce89hkg9jm0l316cu/1588477425000/13158967983899698144/12760646577352524255Z/18cyWOHXhenkCD1Fiyct-_7pZXRfnK2Yv?e=download [following]\n",
            "--2020-05-03 03:44:56--  https://doc-10-4k-docs.googleusercontent.com/docs/securesc/2d2i9c4pjd8noh2kmtrrgddb5s319ckl/s3t06c5kusr0pq0ce89hkg9jm0l316cu/1588477425000/13158967983899698144/12760646577352524255Z/18cyWOHXhenkCD1Fiyct-_7pZXRfnK2Yv?e=download\n",
            "Resolving doc-10-4k-docs.googleusercontent.com (doc-10-4k-docs.googleusercontent.com)... 64.233.188.132, 2404:6800:4008:c06::84\n",
            "Connecting to doc-10-4k-docs.googleusercontent.com (doc-10-4k-docs.googleusercontent.com)|64.233.188.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=4jjpstp8hh58q&continue=https://doc-10-4k-docs.googleusercontent.com/docs/securesc/2d2i9c4pjd8noh2kmtrrgddb5s319ckl/s3t06c5kusr0pq0ce89hkg9jm0l316cu/1588477425000/13158967983899698144/12760646577352524255Z/18cyWOHXhenkCD1Fiyct-_7pZXRfnK2Yv?e%3Ddownload&hash=dnl2d2j262oi5i6i5gik0c8tn31n1mi4 [following]\n",
            "--2020-05-03 03:44:56--  https://docs.google.com/nonceSigner?nonce=4jjpstp8hh58q&continue=https://doc-10-4k-docs.googleusercontent.com/docs/securesc/2d2i9c4pjd8noh2kmtrrgddb5s319ckl/s3t06c5kusr0pq0ce89hkg9jm0l316cu/1588477425000/13158967983899698144/12760646577352524255Z/18cyWOHXhenkCD1Fiyct-_7pZXRfnK2Yv?e%3Ddownload&hash=dnl2d2j262oi5i6i5gik0c8tn31n1mi4\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.203.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-10-4k-docs.googleusercontent.com/docs/securesc/2d2i9c4pjd8noh2kmtrrgddb5s319ckl/s3t06c5kusr0pq0ce89hkg9jm0l316cu/1588477425000/13158967983899698144/12760646577352524255Z/18cyWOHXhenkCD1Fiyct-_7pZXRfnK2Yv?e=download&nonce=4jjpstp8hh58q&user=12760646577352524255Z&hash=rrebln6rud7qsooru25s079de84bsc3j [following]\n",
            "--2020-05-03 03:44:56--  https://doc-10-4k-docs.googleusercontent.com/docs/securesc/2d2i9c4pjd8noh2kmtrrgddb5s319ckl/s3t06c5kusr0pq0ce89hkg9jm0l316cu/1588477425000/13158967983899698144/12760646577352524255Z/18cyWOHXhenkCD1Fiyct-_7pZXRfnK2Yv?e=download&nonce=4jjpstp8hh58q&user=12760646577352524255Z&hash=rrebln6rud7qsooru25s079de84bsc3j\n",
            "Connecting to doc-10-4k-docs.googleusercontent.com (doc-10-4k-docs.googleusercontent.com)|64.233.188.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘data2D.zip’\n",
            "\n",
            "data2D.zip              [    <=>             ]  57.41M  45.0MB/s    in 1.3s    \n",
            "\n",
            "2020-05-03 03:44:58 (45.0 MB/s) - ‘data2D.zip’ saved [60202424]\n",
            "\n",
            "--2020-05-03 03:45:01--  https://docs.google.com/uc?export=download&confirm=i3x8&id=1q_NULDeoIHmZTPeMCiGMFOnxP5v0o4vf\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.203.102, 74.125.203.138, 74.125.203.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.203.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0g-0k-docs.googleusercontent.com/docs/securesc/ksoa7mc08i1e7ea3d2vbi8e5hioip658/5lhj2546b99q0pclqjjsf3h7j8lsplos/1588477500000/13158967983899698144/16048459886287641100Z/1q_NULDeoIHmZTPeMCiGMFOnxP5v0o4vf?e=download [following]\n",
            "--2020-05-03 03:45:01--  https://doc-0g-0k-docs.googleusercontent.com/docs/securesc/ksoa7mc08i1e7ea3d2vbi8e5hioip658/5lhj2546b99q0pclqjjsf3h7j8lsplos/1588477500000/13158967983899698144/16048459886287641100Z/1q_NULDeoIHmZTPeMCiGMFOnxP5v0o4vf?e=download\n",
            "Resolving doc-0g-0k-docs.googleusercontent.com (doc-0g-0k-docs.googleusercontent.com)... 64.233.188.132, 2404:6800:4008:c06::84\n",
            "Connecting to doc-0g-0k-docs.googleusercontent.com (doc-0g-0k-docs.googleusercontent.com)|64.233.188.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=3blqhn1s4dv9k&continue=https://doc-0g-0k-docs.googleusercontent.com/docs/securesc/ksoa7mc08i1e7ea3d2vbi8e5hioip658/5lhj2546b99q0pclqjjsf3h7j8lsplos/1588477500000/13158967983899698144/16048459886287641100Z/1q_NULDeoIHmZTPeMCiGMFOnxP5v0o4vf?e%3Ddownload&hash=ftrtmqqbc81sh3d23f1bn9t6ctltou57 [following]\n",
            "--2020-05-03 03:45:01--  https://docs.google.com/nonceSigner?nonce=3blqhn1s4dv9k&continue=https://doc-0g-0k-docs.googleusercontent.com/docs/securesc/ksoa7mc08i1e7ea3d2vbi8e5hioip658/5lhj2546b99q0pclqjjsf3h7j8lsplos/1588477500000/13158967983899698144/16048459886287641100Z/1q_NULDeoIHmZTPeMCiGMFOnxP5v0o4vf?e%3Ddownload&hash=ftrtmqqbc81sh3d23f1bn9t6ctltou57\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.203.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-0g-0k-docs.googleusercontent.com/docs/securesc/ksoa7mc08i1e7ea3d2vbi8e5hioip658/5lhj2546b99q0pclqjjsf3h7j8lsplos/1588477500000/13158967983899698144/16048459886287641100Z/1q_NULDeoIHmZTPeMCiGMFOnxP5v0o4vf?e=download&nonce=3blqhn1s4dv9k&user=16048459886287641100Z&hash=atgial4l4busg8u9ij89rhju53sjosau [following]\n",
            "--2020-05-03 03:45:03--  https://doc-0g-0k-docs.googleusercontent.com/docs/securesc/ksoa7mc08i1e7ea3d2vbi8e5hioip658/5lhj2546b99q0pclqjjsf3h7j8lsplos/1588477500000/13158967983899698144/16048459886287641100Z/1q_NULDeoIHmZTPeMCiGMFOnxP5v0o4vf?e=download&nonce=3blqhn1s4dv9k&user=16048459886287641100Z&hash=atgial4l4busg8u9ij89rhju53sjosau\n",
            "Connecting to doc-0g-0k-docs.googleusercontent.com (doc-0g-0k-docs.googleusercontent.com)|64.233.188.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘data1D.zip’\n",
            "\n",
            "data1D.zip              [     <=>            ]  90.30M  52.5MB/s    in 1.7s    \n",
            "\n",
            "2020-05-03 03:45:05 (52.5 MB/s) - ‘data1D.zip’ saved [94690949]\n",
            "\n",
            "Archive:  data2D.zip\n",
            "  inflating: data.pkl                \n",
            "Archive:  data1D.zip\n",
            "  inflating: data1D.pkl              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0nRWBBGtRus",
        "colab_type": "text"
      },
      "source": [
        "# **Gender recognition through speech**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAl91vzdq-l6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from time import time\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "import h5py\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import os\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDbjAXOisSST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def barplot_model(labels,train,test,ylabel='Accuracy',\n",
        "                       title='Accuracy obtained in each architecture', \n",
        "                  lab1='Acc. train',lab2='Acc. test'): \n",
        "    x = np.arange(len(labels))  # the label locations\n",
        "    width = 0.35  # the width of the bars\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10,7))\n",
        "    rects1 = ax.bar(x - width/2, train, width, label=lab1)\n",
        "    rects2 = ax.bar(x + width/2, test, width, label=lab2)\n",
        "\n",
        "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "    ax.set_ylabel(ylabel)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.legend()\n",
        "    \n",
        "    def autolabel(rects):\n",
        "        for rect in rects:\n",
        "            height = rect.get_height()\n",
        "            ax.annotate('{:.2f}'.format(height),\n",
        "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                        xytext=(0, 3),  # 3 points vertical offset\n",
        "                        textcoords=\"offset points\",\n",
        "                        ha='center', va='bottom')\n",
        "    autolabel(rects1)\n",
        "    autolabel(rects2)\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nakg4jssk3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WC7s-e8xMaY",
        "colab_type": "text"
      },
      "source": [
        "# **2D convolution over spectrograms**\n",
        "\n",
        "The amount of neurons of the last 2 fully-connected layers is configurable. Three different values are tested in this exercise. Batch normalization is an additional parameter that could be selected.\n",
        "\n",
        "A first try was made wit more complex convolutional models, but accuracies in validation and train did nos reach more than 50%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV8eBA0L_If7",
        "colab_type": "code",
        "outputId": "b721f49b-79db-45e3-df76-3e9895da04b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "def barplot_model(labels,train,test,ylabel='Accuracy',\n",
        "                       title='Accuracy obtained in each architecture', \n",
        "                  lab1='Acc. train',lab2='Acc. test'): \n",
        "    x = np.arange(len(labels))  # the label locations\n",
        "    width = 0.35  # the width of the bars\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10,7))\n",
        "    rects1 = ax.bar(x - width/2, train, width, label=lab1)\n",
        "    rects2 = ax.bar(x + width/2, test, width, label=lab2)\n",
        "\n",
        "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "    ax.set_ylabel(ylabel)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.legend()\n",
        "    \n",
        "    def autolabel(rects):\n",
        "        for rect in rects:\n",
        "            height = rect.get_height()\n",
        "            ax.annotate('{:.2f}'.format(height),\n",
        "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                        xytext=(0, 3),  # 3 points vertical offset\n",
        "                        textcoords=\"offset points\",\n",
        "                        ha='center', va='bottom')\n",
        "    autolabel(rects1)\n",
        "    autolabel(rects2)\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "def get_conv_model_2DL(num_classes,bn=False,neurons=[256,64],compile=True):\n",
        "    print(\"using\",num_classes,\"classes\")\n",
        "    inputs = tf.keras.Input(shape=(40,100,3), name=\"input_1\")\n",
        "    layers = tf.keras.layers.Conv2D(32,(7,7),  strides=2)(inputs)\n",
        "    if bn:\n",
        "        layers = tf.keras.layers.BatchNormalization()(layers)\n",
        "    layers = tf.keras.layers.Activation('relu')(layers)\n",
        "    layers = tf.keras.layers.Conv2D(64,(5,5), strides=1,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Conv2D(128,(3,3), strides=1,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Conv2D(256,(3,3), strides=1,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Conv2D(256,(3,3), strides=1,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Flatten()(layers)\n",
        "    layers = tf.keras.layers.Dense(neurons[0], activation=tf.nn.relu)(layers)\n",
        "    layers = tf.keras.layers.Dense(neurons[1], activation=tf.nn.relu)(layers)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    predictions = tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax, name=\"output_1\")(layers)\n",
        "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
        "    if compile:\n",
        "        model.compile(optimizer='adam',\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "    return model\n",
        "  \n",
        "\n",
        "def train2DL(model, batch_size, epochs, model_name=\"\"):\n",
        "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"2DL/logs/\"+model_name+\"_\"+\"{}\".format(time()))\n",
        "    model.reset_states()\n",
        "    history = model.fit(x_train, y_train, epochs=epochs, callbacks=[tensorboard],\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(x_test, y_test))\n",
        "    metrics = model.evaluate(x_test, y_test)\n",
        "    return {k:v for k,v in zip (model.metrics_names, metrics)}, history.history\n",
        "\n",
        "with open('data.pkl','rb') as g: \n",
        "    y_train_gender, x_train_gender = pickle.load(g)\n",
        "\n",
        "models2DL = {'A':{'bn':False,'layers':[1024,256],'acc':0,'t':0},'B':{'bn':True,'layers':[1024,256],'acc':0,'t':0},\n",
        "          'C':{'bn':False,'layers':[512,128],'acc':0,'t':0},'D':{'bn':True,'layers':[512,128],'acc':0,'t':0},\n",
        "          'E':{'bn':False,'layers':[256,64],'acc':0,'t':0},'F':{'bn':True,'layers':[256,64],'acc':0,'t':0}}\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train_gender, y_train_gender, test_size=.20,stratify=y_train_gender)\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "print(\"\\ndistribution of train classes\")\n",
        "print(pd.Series(y_train).value_counts())\n",
        "print(\"\\ndistribution of test classes\")\n",
        "print(pd.Series(y_test).value_counts())\n",
        "\n",
        "for key in models2DL:\n",
        "    start_time = time()\n",
        "    modelX = get_conv_model_2DL(2,models2DL[key]['bn'],models2DL[key]['layers'])\n",
        "    print(modelX.summary())\n",
        "    results, models2DL[key]['acc'] = train2DL(modelX, batch_size=32, epochs=15, model_name=key)\n",
        "    models2DL[key]['t'] = time() - start_time\n",
        "\n",
        "labels=[]\n",
        "at2l=[]\n",
        "lt2l=[]\n",
        "av2l=[]\n",
        "lv2l=[]\n",
        "t2dl=[]\n",
        "for key in models2DL:\n",
        "    labels.append(key)\n",
        "    j = models2DL[key]['acc']['val_accuracy'].index(max(models2DL[key]['acc']['val_accuracy']))\n",
        "    at2l.append(models2DL[key]['acc']['accuracy'][j])\n",
        "    lt2l.append(models2DL[key]['acc']['loss'][j])\n",
        "    av2l.append(models2DL[key]['acc']['val_accuracy'][j])\n",
        "    lv2l.append(models2DL[key]['acc']['val_loss'][j])\n",
        "    t2dl.append(models2DL[key]['t'])\n",
        "\n",
        "barplot_model(labels,at2l,av2l)   \n",
        "barplot_model(labels,lt2l,lv2l,ylabel='Loss',title='Loss obtained in each architecture',\n",
        "              lab1='Loss train',lab2='Loss test')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(999, 40, 100, 3) (999,) (250, 40, 100, 3) (250,)\n",
            "\n",
            "distribution of train classes\n",
            "1    520\n",
            "0    479\n",
            "dtype: int64\n",
            "\n",
            "distribution of test classes\n",
            "1    130\n",
            "0    120\n",
            "dtype: int64\n",
            "using 2 classes\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 40, 100, 3)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 17, 47, 32)        4736      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 17, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 13, 43, 64)        51264     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 41, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 9, 39, 256)        295168    \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 7, 37, 256)        590080    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 66304)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              67896320  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 69,174,338\n",
            "Trainable params: 69,174,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "32/32 [==============================] - 60s 2s/step - loss: 2.6872 - accuracy: 0.4885 - val_loss: 0.6933 - val_accuracy: 0.4800\n",
            "Epoch 2/15\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.6933 - accuracy: 0.4975 - val_loss: 0.6927 - val_accuracy: 0.5200\n",
            "Epoch 3/15\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.6927 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 4/15\n",
            "32/32 [==============================] - 63s 2s/step - loss: 0.6922 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 5/15\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.6922 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 6/15\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.6927 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5200\n",
            "Epoch 7/15\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.6919 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 8/15\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.6923 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 9/15\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.6920 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 10/15\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.6925 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 11/15\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.6923 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 12/15\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.6926 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 13/15\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.6927 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 14/15\n",
            "32/32 [==============================] - 62s 2s/step - loss: 0.6918 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 15/15\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.6924 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "8/8 [==============================] - 3s 372ms/step - loss: 0.6924 - accuracy: 0.5200\n",
            "using 2 classes\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 40, 100, 3)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 17, 47, 32)        4736      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 17, 47, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 17, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 13, 43, 64)        51264     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 11, 41, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 9, 39, 256)        295168    \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 7, 37, 256)        590080    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 66304)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              67896320  \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 69,174,466\n",
            "Trainable params: 69,174,402\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.9885 - accuracy: 0.5185 - val_loss: 0.6925 - val_accuracy: 0.5200\n",
            "Epoch 2/15\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.6928 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 3/15\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.6928 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 4/15\n",
            "32/32 [==============================] - 59s 2s/step - loss: 0.6928 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 5/15\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.6927 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 6/15\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.6925 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 7/15\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.6932 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 8/15\n",
            "32/32 [==============================] - 61s 2s/step - loss: 0.6928 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5200\n",
            "Epoch 9/15\n",
            "32/32 [==============================] - 63s 2s/step - loss: 0.6923 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 10/15\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.6921 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 11/15\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.6931 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 12/15\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.6920 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 13/15\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.6919 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 14/15\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.6922 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 15/15\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.6921 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "8/8 [==============================] - 3s 382ms/step - loss: 0.6924 - accuracy: 0.5200\n",
            "using 2 classes\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 40, 100, 3)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 17, 47, 32)        4736      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 17, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 13, 43, 64)        51264     \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 11, 41, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 9, 39, 256)        295168    \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 7, 37, 256)        590080    \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 66304)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               33948160  \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 35,029,186\n",
            "Trainable params: 35,029,186\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 2.2923 - accuracy: 0.4825 - val_loss: 0.6928 - val_accuracy: 0.5200\n",
            "Epoch 2/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6931 - accuracy: 0.5205 - val_loss: 0.6926 - val_accuracy: 0.5200\n",
            "Epoch 3/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6926 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5200\n",
            "Epoch 4/15\n",
            "32/32 [==============================] - 54s 2s/step - loss: 0.6924 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 5/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6927 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 6/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6925 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 7/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6930 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 8/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6922 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 9/15\n",
            "32/32 [==============================] - 48s 2s/step - loss: 0.6920 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 10/15\n",
            "32/32 [==============================] - 48s 2s/step - loss: 0.6920 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 11/15\n",
            "32/32 [==============================] - 48s 2s/step - loss: 0.6919 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 12/15\n",
            "32/32 [==============================] - 48s 2s/step - loss: 0.6927 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 13/15\n",
            "32/32 [==============================] - 48s 2s/step - loss: 0.6927 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 14/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6926 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 15/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6927 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "8/8 [==============================] - 3s 328ms/step - loss: 0.6924 - accuracy: 0.5200\n",
            "using 2 classes\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 40, 100, 3)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 17, 47, 32)        4736      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 17, 47, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 17, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 13, 43, 64)        51264     \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 11, 41, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 9, 39, 256)        295168    \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 7, 37, 256)        590080    \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 66304)             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               33948160  \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 35,029,314\n",
            "Trainable params: 35,029,250\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "32/32 [==============================] - 52s 2s/step - loss: 0.9086 - accuracy: 0.5195 - val_loss: 0.6927 - val_accuracy: 0.5200\n",
            "Epoch 2/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6929 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5200\n",
            "Epoch 3/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6924 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 4/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6923 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 5/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6921 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 6/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6926 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 7/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6933 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 8/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6928 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 9/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6921 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 10/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6927 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5200\n",
            "Epoch 11/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6926 - accuracy: 0.5195 - val_loss: 0.6925 - val_accuracy: 0.5200\n",
            "Epoch 12/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6923 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 13/15\n",
            "32/32 [==============================] - 52s 2s/step - loss: 0.6928 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 14/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6925 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 15/15\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6926 - accuracy: 0.5215 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "8/8 [==============================] - 3s 329ms/step - loss: 0.6924 - accuracy: 0.5200\n",
            "using 2 classes\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 40, 100, 3)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 17, 47, 32)        4736      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 17, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 13, 43, 64)        51264     \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 11, 41, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 9, 39, 256)        295168    \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 7, 37, 256)        590080    \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 66304)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 256)               16974080  \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 18,005,762\n",
            "Trainable params: 18,005,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 1.5022 - accuracy: 0.4955 - val_loss: 0.6933 - val_accuracy: 0.4800\n",
            "Epoch 2/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6943 - accuracy: 0.4875 - val_loss: 0.6929 - val_accuracy: 0.5200\n",
            "Epoch 3/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6930 - accuracy: 0.5205 - val_loss: 0.6926 - val_accuracy: 0.5200\n",
            "Epoch 4/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6927 - accuracy: 0.5205 - val_loss: 0.6926 - val_accuracy: 0.5200\n",
            "Epoch 5/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6925 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5200\n",
            "Epoch 6/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6927 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5200\n",
            "Epoch 7/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6930 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 8/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6926 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 9/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6931 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 10/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6925 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 11/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6925 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5200\n",
            "Epoch 12/15\n",
            "32/32 [==============================] - 47s 1s/step - loss: 0.6930 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 13/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6924 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 14/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6933 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 15/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6922 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "8/8 [==============================] - 2s 306ms/step - loss: 0.6924 - accuracy: 0.5200\n",
            "using 2 classes\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 40, 100, 3)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 17, 47, 32)        4736      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 17, 47, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 17, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 13, 43, 64)        51264     \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 11, 41, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 9, 39, 256)        295168    \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 7, 37, 256)        590080    \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 66304)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 256)               16974080  \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 18,005,890\n",
            "Trainable params: 18,005,826\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "32/32 [==============================] - 45s 1s/step - loss: 0.9778 - accuracy: 0.4494 - val_loss: 0.6932 - val_accuracy: 0.4800\n",
            "Epoch 2/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6943 - accuracy: 0.5105 - val_loss: 0.6929 - val_accuracy: 0.5200\n",
            "Epoch 3/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6930 - accuracy: 0.5205 - val_loss: 0.6927 - val_accuracy: 0.5200\n",
            "Epoch 4/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6929 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5200\n",
            "Epoch 5/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6924 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5200\n",
            "Epoch 6/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6927 - accuracy: 0.5195 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 7/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6926 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 8/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6924 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 9/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6919 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 10/15\n",
            "32/32 [==============================] - 47s 1s/step - loss: 0.6931 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 11/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6921 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 12/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6921 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 13/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6930 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 14/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6921 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "Epoch 15/15\n",
            "32/32 [==============================] - 44s 1s/step - loss: 0.6923 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
            "8/8 [==============================] - 2s 309ms/step - loss: 0.6924 - accuracy: 0.5200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvaU3NC67mHk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "ec00f44d-27f4-4d37-fa78-51d3c056bbf6"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(labels,t2dl)\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faNi2Uw2pv0f",
        "colab_type": "text"
      },
      "source": [
        "After trying with different sizes for filters and values for strides, some models end up with amount of parameters that could not be trained in collab or in personal computers. The problem seems to be easier and only one convolutional layer was used and tuned. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy5hLk4Wt4Zi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_conv_model_2D(num_classes,bn=False,neurons=[256,64],compile=True):\n",
        "    print(\"using\",num_classes,\"classes\")\n",
        "    inputs = tf.keras.Input(shape=(40,100,3), name=\"input_1\")\n",
        "    layers = tf.keras.layers.Conv2D(32,(3,3),  strides=1)(inputs)\n",
        "    if bn:\n",
        "        layers = tf.keras.layers.BatchNormalization()(layers)\n",
        "    layers = tf.keras.layers.Activation('relu')(layers)\n",
        "    layers = tf.keras.layers.Flatten()(layers)\n",
        "    layers = tf.keras.layers.Dense(neurons[0], activation=tf.nn.relu)(layers)\n",
        "    layers = tf.keras.layers.Dense(neurons[1], activation=tf.nn.relu)(layers)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    predictions = tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax, name=\"output_1\")(layers)\n",
        "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
        "    if compile:\n",
        "        model.compile(optimizer='adam',\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XE_zBniylho",
        "colab_type": "text"
      },
      "source": [
        "Both, accuracy and loss are saved for displaying in tensorboard. Also, a checkpoint is made for saving the best model in terms of validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmLHf00P-8DA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train2D(model, batch_size, epochs, model_name=\"\"):\n",
        "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"2D/logs/\"+model_name+\"_\"+\"{}\".format(time()))\n",
        "    model.reset_states()\n",
        "    checkpoint = ModelCheckpoint(\"2D/\"+model_name+\".hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1)\n",
        "    history = model.fit(x_train, y_train, epochs=epochs, callbacks=[tensorboard, checkpoint],\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(x_test, y_test))\n",
        "    metrics = model.evaluate(x_test, y_test)\n",
        "    return {k:v for k,v in zip (model.metrics_names, metrics)}, history.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf-XHvnRzD2C",
        "colab_type": "text"
      },
      "source": [
        "An input of the neural network is consists in 3 images of size 40x100. The first image is the spectrogram computed from an audio of 1 second long. The second and third images are the first and second derivatives of the spectrogram, respectively. \n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgkxMZLbuQCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data.pkl','rb') as g: \n",
        "    y_train_gender, x_train_gender = pickle.load(g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgyPOI8_ubG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models2D = {'A':{'bn':False,'layers':[1024,256],'acc':0,'t':0},'B':{'bn':True,'layers':[1024,256],'acc':0,'t':0},\n",
        "          'C':{'bn':False,'layers':[512,128],'acc':0,'t':0},'D':{'bn':True,'layers':[512,128],'acc':0,'t':0},\n",
        "          'E':{'bn':False,'layers':[256,64],'acc':0,'t':0},'F':{'bn':True,'layers':[256,64],'acc':0,'t':0}}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sUHYvhq00QC",
        "colab_type": "text"
      },
      "source": [
        "The dataset consists of 1200 audios that were randomly selected from the original database. Form this dataset 80% is used for training and 20% for test in a stratified way. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdzyMG5Aucny",
        "colab_type": "code",
        "outputId": "fd7895c5-057d-416b-bc19-2cadb026dfbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_train_gender, y_train_gender, test_size=.20,stratify=y_train_gender)\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "print(\"\\ndistribution of train classes\")\n",
        "print(pd.Series(y_train).value_counts())\n",
        "print(\"\\ndistribution of test classes\")\n",
        "print(pd.Series(y_test).value_counts())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(999, 40, 100, 3) (999,) (250, 40, 100, 3) (250,)\n",
            "\n",
            "distribution of train classes\n",
            "1    520\n",
            "0    479\n",
            "dtype: int64\n",
            "\n",
            "distribution of test classes\n",
            "1    130\n",
            "0    120\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGNId_sHuu2y",
        "colab_type": "code",
        "outputId": "925ace10-75fc-46f0-839e-42806dc7292a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for key in models2D:\n",
        "    start_time = time()\n",
        "    modelX = get_conv_model_2D(2,models2D[key]['bn'],models2D[key]['layers'])\n",
        "    print(modelX.summary())\n",
        "    results, models2D[key]['acc'] = train2D(modelX, batch_size=32, epochs=15, model_name=key)\n",
        "    models2D[key]['t'] = time() - start_time\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using 2 classes\n",
            "Model: \"model_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 40, 100, 3)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 38, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 38, 98, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_24 (Flatten)         (None, 119168)            0         \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 1024)              122029056 \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 122,292,866\n",
            "Trainable params: 122,292,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/15\n",
            "32/32 [==============================] - ETA: 0s - loss: 44.6210 - accuracy: 0.5285\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.62400, saving model to 2D/A.hdf5\n",
            "32/32 [==============================] - 7s 204ms/step - loss: 44.6210 - accuracy: 0.5285 - val_loss: 2.4102 - val_accuracy: 0.6240\n",
            "Epoch 2/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 2.3995 - accuracy: 0.7107\n",
            "Epoch 00002: val_accuracy did not improve from 0.62400\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 2.3317 - accuracy: 0.7117 - val_loss: 4.2496 - val_accuracy: 0.5240\n",
            "Epoch 3/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 1.4242 - accuracy: 0.7389\n",
            "Epoch 00003: val_accuracy improved from 0.62400 to 0.86000, saving model to 2D/A.hdf5\n",
            "32/32 [==============================] - 38s 1s/step - loss: 1.3888 - accuracy: 0.7397 - val_loss: 0.4184 - val_accuracy: 0.8600\n",
            "Epoch 4/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.4435 - accuracy: 0.8448\n",
            "Epoch 00004: val_accuracy did not improve from 0.86000\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.4368 - accuracy: 0.8448 - val_loss: 0.5071 - val_accuracy: 0.8040\n",
            "Epoch 5/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.2718 - accuracy: 0.8871\n",
            "Epoch 00005: val_accuracy did not improve from 0.86000\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.2645 - accuracy: 0.8879 - val_loss: 0.3866 - val_accuracy: 0.8520\n",
            "Epoch 6/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1935 - accuracy: 0.9183\n",
            "Epoch 00006: val_accuracy did not improve from 0.86000\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.2169 - accuracy: 0.9169 - val_loss: 0.4694 - val_accuracy: 0.8520\n",
            "Epoch 7/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1597 - accuracy: 0.9355\n",
            "Epoch 00007: val_accuracy did not improve from 0.86000\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.1623 - accuracy: 0.9349 - val_loss: 0.5412 - val_accuracy: 0.7880\n",
            "Epoch 8/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1217 - accuracy: 0.9496\n",
            "Epoch 00008: val_accuracy did not improve from 0.86000\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.1190 - accuracy: 0.9499 - val_loss: 0.5316 - val_accuracy: 0.8360\n",
            "Epoch 9/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0791 - accuracy: 0.9708\n",
            "Epoch 00009: val_accuracy did not improve from 0.86000\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.0770 - accuracy: 0.9710 - val_loss: 0.5490 - val_accuracy: 0.8200\n",
            "Epoch 10/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0478 - accuracy: 0.9849\n",
            "Epoch 00010: val_accuracy did not improve from 0.86000\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.0463 - accuracy: 0.9850 - val_loss: 1.2186 - val_accuracy: 0.7600\n",
            "Epoch 11/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0566 - accuracy: 0.9819\n",
            "Epoch 00011: val_accuracy did not improve from 0.86000\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.0549 - accuracy: 0.9820 - val_loss: 0.7469 - val_accuracy: 0.8320\n",
            "Epoch 12/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9919\n",
            "Epoch 00012: val_accuracy did not improve from 0.86000\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.0202 - accuracy: 0.9920 - val_loss: 0.7354 - val_accuracy: 0.8320\n",
            "Epoch 13/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9980\n",
            "Epoch 00013: val_accuracy did not improve from 0.86000\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.0113 - accuracy: 0.9980 - val_loss: 0.8242 - val_accuracy: 0.8360\n",
            "Epoch 14/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9990\n",
            "Epoch 00014: val_accuracy did not improve from 0.86000\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 1.2177 - val_accuracy: 0.7920\n",
            "Epoch 15/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9909\n",
            "Epoch 00015: val_accuracy did not improve from 0.86000\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.0190 - accuracy: 0.9910 - val_loss: 0.8918 - val_accuracy: 0.8280\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8918 - accuracy: 0.8280\n",
            "using 2 classes\n",
            "Model: \"model_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 40, 100, 3)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 38, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 38, 98, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 38, 98, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_25 (Flatten)         (None, 119168)            0         \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 1024)              122029056 \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 122,292,994\n",
            "Trainable params: 122,292,930\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/15\n",
            "32/32 [==============================] - ETA: 0s - loss: 26.8233 - accuracy: 0.5656\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.56000, saving model to 2D/B.hdf5\n",
            "32/32 [==============================] - 24s 763ms/step - loss: 26.8233 - accuracy: 0.5656 - val_loss: 7.5572 - val_accuracy: 0.5600\n",
            "Epoch 2/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 2.2920 - accuracy: 0.7671\n",
            "Epoch 00002: val_accuracy did not improve from 0.56000\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 2.2670 - accuracy: 0.7678 - val_loss: 3.3888 - val_accuracy: 0.5520\n",
            "Epoch 3/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.5967 - accuracy: 0.8498\n",
            "Epoch 00003: val_accuracy improved from 0.56000 to 0.76800, saving model to 2D/B.hdf5\n",
            "32/32 [==============================] - 40s 1s/step - loss: 0.6351 - accuracy: 0.8488 - val_loss: 0.6168 - val_accuracy: 0.7680\n",
            "Epoch 4/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.3142 - accuracy: 0.8821\n",
            "Epoch 00004: val_accuracy did not improve from 0.76800\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.3050 - accuracy: 0.8829 - val_loss: 0.8665 - val_accuracy: 0.5920\n",
            "Epoch 5/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.2160 - accuracy: 0.9123\n",
            "Epoch 00005: val_accuracy did not improve from 0.76800\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.2117 - accuracy: 0.9129 - val_loss: 0.7170 - val_accuracy: 0.7240\n",
            "Epoch 6/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1532 - accuracy: 0.9425\n",
            "Epoch 00006: val_accuracy improved from 0.76800 to 0.81200, saving model to 2D/B.hdf5\n",
            "32/32 [==============================] - 35s 1s/step - loss: 0.1592 - accuracy: 0.9419 - val_loss: 0.4579 - val_accuracy: 0.8120\n",
            "Epoch 7/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1039 - accuracy: 0.9617\n",
            "Epoch 00007: val_accuracy did not improve from 0.81200\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.1079 - accuracy: 0.9620 - val_loss: 0.5209 - val_accuracy: 0.7600\n",
            "Epoch 8/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1038 - accuracy: 0.9567\n",
            "Epoch 00008: val_accuracy did not improve from 0.81200\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.1007 - accuracy: 0.9570 - val_loss: 0.5716 - val_accuracy: 0.8080\n",
            "Epoch 9/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0758 - accuracy: 0.9677\n",
            "Epoch 00009: val_accuracy improved from 0.81200 to 0.85600, saving model to 2D/B.hdf5\n",
            "32/32 [==============================] - 32s 1s/step - loss: 0.0763 - accuracy: 0.9680 - val_loss: 0.5442 - val_accuracy: 0.8560\n",
            "Epoch 10/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0480 - accuracy: 0.9833\n",
            "Epoch 00010: val_accuracy did not improve from 0.85600\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 0.0476 - accuracy: 0.9830 - val_loss: 0.5130 - val_accuracy: 0.8320\n",
            "Epoch 11/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0392 - accuracy: 0.9909\n",
            "Epoch 00011: val_accuracy did not improve from 0.85600\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.0381 - accuracy: 0.9910 - val_loss: 0.5004 - val_accuracy: 0.8480\n",
            "Epoch 12/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0477 - accuracy: 0.9819\n",
            "Epoch 00012: val_accuracy did not improve from 0.85600\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.0467 - accuracy: 0.9820 - val_loss: 0.6550 - val_accuracy: 0.8200\n",
            "Epoch 13/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9950\n",
            "Epoch 00013: val_accuracy did not improve from 0.85600\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 0.0186 - accuracy: 0.9950 - val_loss: 0.6366 - val_accuracy: 0.8400\n",
            "Epoch 14/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9950\n",
            "Epoch 00014: val_accuracy did not improve from 0.85600\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.5910 - val_accuracy: 0.8400\n",
            "Epoch 15/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9929\n",
            "Epoch 00015: val_accuracy did not improve from 0.85600\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.0161 - accuracy: 0.9930 - val_loss: 0.7158 - val_accuracy: 0.8280\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7158 - accuracy: 0.8280\n",
            "using 2 classes\n",
            "Model: \"model_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 40, 100, 3)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 38, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 38, 98, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_26 (Flatten)         (None, 119168)            0         \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 512)               61014528  \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 61,081,346\n",
            "Trainable params: 61,081,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 60.6756 - accuracy: 0.5480\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.52000, saving model to 2D/C.hdf5\n",
            "32/32 [==============================] - 13s 413ms/step - loss: 54.3993 - accuracy: 0.5516 - val_loss: 19.5759 - val_accuracy: 0.5200\n",
            "Epoch 2/15\n",
            "32/32 [==============================] - ETA: 0s - loss: 6.5192 - accuracy: 0.5275\n",
            "Epoch 00002: val_accuracy did not improve from 0.52000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 6.5192 - accuracy: 0.5275 - val_loss: 1.8664 - val_accuracy: 0.4800\n",
            "Epoch 3/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.8794 - accuracy: 0.6442\n",
            "Epoch 00003: val_accuracy improved from 0.52000 to 0.60400, saving model to 2D/C.hdf5\n",
            "32/32 [==============================] - 18s 563ms/step - loss: 0.8742 - accuracy: 0.6426 - val_loss: 0.6030 - val_accuracy: 0.6040\n",
            "Epoch 4/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.6440 - accuracy: 0.6292\n",
            "Epoch 00004: val_accuracy improved from 0.60400 to 0.78800, saving model to 2D/C.hdf5\n",
            "32/32 [==============================] - 21s 656ms/step - loss: 0.6440 - accuracy: 0.6336 - val_loss: 0.5618 - val_accuracy: 0.7880\n",
            "Epoch 5/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.5492 - accuracy: 0.7208\n",
            "Epoch 00005: val_accuracy improved from 0.78800 to 0.81600, saving model to 2D/C.hdf5\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.5441 - accuracy: 0.7257 - val_loss: 0.5099 - val_accuracy: 0.8160\n",
            "Epoch 6/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.4658 - accuracy: 0.7844\n",
            "Epoch 00006: val_accuracy did not improve from 0.81600\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.4829 - accuracy: 0.7788 - val_loss: 0.5158 - val_accuracy: 0.7840\n",
            "Epoch 7/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.4522 - accuracy: 0.7853\n",
            "Epoch 00007: val_accuracy improved from 0.81600 to 0.83200, saving model to 2D/C.hdf5\n",
            "32/32 [==============================] - 19s 597ms/step - loss: 0.4517 - accuracy: 0.7848 - val_loss: 0.4664 - val_accuracy: 0.8320\n",
            "Epoch 8/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.3186 - accuracy: 0.8710\n",
            "Epoch 00008: val_accuracy did not improve from 0.83200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.3226 - accuracy: 0.8699 - val_loss: 0.4470 - val_accuracy: 0.8120\n",
            "Epoch 9/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.2541 - accuracy: 0.8984\n",
            "Epoch 00009: val_accuracy did not improve from 0.83200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.2576 - accuracy: 0.8979 - val_loss: 0.4874 - val_accuracy: 0.7840\n",
            "Epoch 10/15\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1898 - accuracy: 0.9119\n",
            "Epoch 00010: val_accuracy did not improve from 0.83200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.1898 - accuracy: 0.9119 - val_loss: 0.5163 - val_accuracy: 0.8200\n",
            "Epoch 11/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.2034 - accuracy: 0.9129\n",
            "Epoch 00011: val_accuracy did not improve from 0.83200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.1905 - accuracy: 0.9189 - val_loss: 0.5490 - val_accuracy: 0.8240\n",
            "Epoch 12/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.2194 - accuracy: 0.9183\n",
            "Epoch 00012: val_accuracy did not improve from 0.83200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.2165 - accuracy: 0.9189 - val_loss: 0.6011 - val_accuracy: 0.7840\n",
            "Epoch 13/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 0.9597\n",
            "Epoch 00013: val_accuracy did not improve from 0.83200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.1282 - accuracy: 0.9580 - val_loss: 0.5010 - val_accuracy: 0.8320\n",
            "Epoch 14/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1142 - accuracy: 0.9567\n",
            "Epoch 00014: val_accuracy did not improve from 0.83200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.1112 - accuracy: 0.9570 - val_loss: 0.6439 - val_accuracy: 0.8080\n",
            "Epoch 15/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0835 - accuracy: 0.9708\n",
            "Epoch 00015: val_accuracy did not improve from 0.83200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0816 - accuracy: 0.9710 - val_loss: 0.6511 - val_accuracy: 0.8120\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.8120\n",
            "using 2 classes\n",
            "Model: \"model_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 40, 100, 3)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 38, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 38, 98, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 38, 98, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_27 (Flatten)         (None, 119168)            0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 512)               61014528  \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 61,081,474\n",
            "Trainable params: 61,081,410\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/15\n",
            "32/32 [==============================] - ETA: 0s - loss: 10.8284 - accuracy: 0.6026\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.48000, saving model to 2D/D.hdf5\n",
            "32/32 [==============================] - 14s 440ms/step - loss: 10.8284 - accuracy: 0.6026 - val_loss: 6.6029 - val_accuracy: 0.4800\n",
            "Epoch 2/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 1.0389 - accuracy: 0.7833\n",
            "Epoch 00002: val_accuracy did not improve from 0.48000\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.0425 - accuracy: 0.7838 - val_loss: 2.9232 - val_accuracy: 0.4800\n",
            "Epoch 3/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.4142 - accuracy: 0.8649\n",
            "Epoch 00003: val_accuracy did not improve from 0.48000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.4036 - accuracy: 0.8659 - val_loss: 2.2075 - val_accuracy: 0.4800\n",
            "Epoch 4/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.2335 - accuracy: 0.9083\n",
            "Epoch 00004: val_accuracy improved from 0.48000 to 0.82000, saving model to 2D/D.hdf5\n",
            "32/32 [==============================] - 17s 530ms/step - loss: 0.2330 - accuracy: 0.9079 - val_loss: 0.4005 - val_accuracy: 0.8200\n",
            "Epoch 5/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1505 - accuracy: 0.9385\n",
            "Epoch 00005: val_accuracy did not improve from 0.82000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.1482 - accuracy: 0.9389 - val_loss: 0.5042 - val_accuracy: 0.7600\n",
            "Epoch 6/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0859 - accuracy: 0.9718\n",
            "Epoch 00006: val_accuracy did not improve from 0.82000\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0835 - accuracy: 0.9720 - val_loss: 0.5290 - val_accuracy: 0.7720\n",
            "Epoch 7/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0514 - accuracy: 0.9819\n",
            "Epoch 00007: val_accuracy improved from 0.82000 to 0.84800, saving model to 2D/D.hdf5\n",
            "32/32 [==============================] - 18s 561ms/step - loss: 0.0533 - accuracy: 0.9810 - val_loss: 0.3898 - val_accuracy: 0.8480\n",
            "Epoch 8/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0453 - accuracy: 0.9865\n",
            "Epoch 00008: val_accuracy improved from 0.84800 to 0.86400, saving model to 2D/D.hdf5\n",
            "32/32 [==============================] - 17s 540ms/step - loss: 0.0446 - accuracy: 0.9860 - val_loss: 0.4222 - val_accuracy: 0.8640\n",
            "Epoch 9/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0486 - accuracy: 0.9808\n",
            "Epoch 00009: val_accuracy did not improve from 0.86400\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0482 - accuracy: 0.9810 - val_loss: 0.4777 - val_accuracy: 0.8400\n",
            "Epoch 10/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.9919\n",
            "Epoch 00010: val_accuracy did not improve from 0.86400\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 0.5210 - val_accuracy: 0.8240\n",
            "Epoch 11/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9950\n",
            "Epoch 00011: val_accuracy did not improve from 0.86400\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0171 - accuracy: 0.9950 - val_loss: 0.5134 - val_accuracy: 0.8160\n",
            "Epoch 12/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9970\n",
            "Epoch 00012: val_accuracy did not improve from 0.86400\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0150 - accuracy: 0.9970 - val_loss: 0.6931 - val_accuracy: 0.7880\n",
            "Epoch 13/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9970\n",
            "Epoch 00013: val_accuracy did not improve from 0.86400\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 0.5687 - val_accuracy: 0.8280\n",
            "Epoch 14/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9980\n",
            "Epoch 00014: val_accuracy did not improve from 0.86400\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.6640 - val_accuracy: 0.8360\n",
            "Epoch 15/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9950\n",
            "Epoch 00015: val_accuracy did not improve from 0.86400\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0136 - accuracy: 0.9950 - val_loss: 0.6036 - val_accuracy: 0.8440\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6036 - accuracy: 0.8440\n",
            "using 2 classes\n",
            "Model: \"model_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 40, 100, 3)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 38, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 38, 98, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_28 (Flatten)         (None, 119168)            0         \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 256)               30507264  \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 30,524,738\n",
            "Trainable params: 30,524,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 46.1460 - accuracy: 0.5312\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.54400, saving model to 2D/E.hdf5\n",
            "32/32 [==============================] - 7s 216ms/step - loss: 42.5143 - accuracy: 0.5245 - val_loss: 0.6845 - val_accuracy: 0.5440\n",
            "Epoch 2/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 1.9746 - accuracy: 0.5427\n",
            "Epoch 00002: val_accuracy did not improve from 0.54400\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.8881 - accuracy: 0.5435 - val_loss: 0.8251 - val_accuracy: 0.5200\n",
            "Epoch 3/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.7275 - accuracy: 0.5813\n",
            "Epoch 00003: val_accuracy did not improve from 0.54400\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7197 - accuracy: 0.5856 - val_loss: 0.6665 - val_accuracy: 0.5360\n",
            "Epoch 4/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.6482 - accuracy: 0.6362\n",
            "Epoch 00004: val_accuracy improved from 0.54400 to 0.71200, saving model to 2D/E.hdf5\n",
            "32/32 [==============================] - 9s 278ms/step - loss: 0.6366 - accuracy: 0.6386 - val_loss: 0.5757 - val_accuracy: 0.7120\n",
            "Epoch 5/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.5442 - accuracy: 0.7338\n",
            "Epoch 00005: val_accuracy did not improve from 0.71200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5412 - accuracy: 0.7377 - val_loss: 0.5794 - val_accuracy: 0.6560\n",
            "Epoch 6/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.4980 - accuracy: 0.7597\n",
            "Epoch 00006: val_accuracy improved from 0.71200 to 0.76000, saving model to 2D/E.hdf5\n",
            "32/32 [==============================] - 10s 308ms/step - loss: 0.4881 - accuracy: 0.7638 - val_loss: 0.4999 - val_accuracy: 0.7600\n",
            "Epoch 7/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.5026 - accuracy: 0.7593\n",
            "Epoch 00007: val_accuracy improved from 0.76000 to 0.83600, saving model to 2D/E.hdf5\n",
            "32/32 [==============================] - 6s 188ms/step - loss: 0.4995 - accuracy: 0.7658 - val_loss: 0.4733 - val_accuracy: 0.8360\n",
            "Epoch 8/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.4174 - accuracy: 0.7984\n",
            "Epoch 00008: val_accuracy did not improve from 0.83600\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4162 - accuracy: 0.7978 - val_loss: 0.4906 - val_accuracy: 0.7440\n",
            "Epoch 9/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.3777 - accuracy: 0.8179\n",
            "Epoch 00009: val_accuracy did not improve from 0.83600\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3865 - accuracy: 0.8108 - val_loss: 0.5038 - val_accuracy: 0.7560\n",
            "Epoch 10/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.3638 - accuracy: 0.8092\n",
            "Epoch 00010: val_accuracy did not improve from 0.83600\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3582 - accuracy: 0.8198 - val_loss: 0.4374 - val_accuracy: 0.8160\n",
            "Epoch 11/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.3195 - accuracy: 0.8351\n",
            "Epoch 00011: val_accuracy did not improve from 0.83600\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3220 - accuracy: 0.8368 - val_loss: 0.4749 - val_accuracy: 0.7920\n",
            "Epoch 12/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.2153 - accuracy: 0.9083\n",
            "Epoch 00012: val_accuracy did not improve from 0.83600\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.2222 - accuracy: 0.9089 - val_loss: 0.4080 - val_accuracy: 0.8360\n",
            "Epoch 13/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1920 - accuracy: 0.9159\n",
            "Epoch 00013: val_accuracy did not improve from 0.83600\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1936 - accuracy: 0.9169 - val_loss: 0.5024 - val_accuracy: 0.7920\n",
            "Epoch 14/15\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1844 - accuracy: 0.9179\n",
            "Epoch 00014: val_accuracy did not improve from 0.83600\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1844 - accuracy: 0.9179 - val_loss: 0.4628 - val_accuracy: 0.8280\n",
            "Epoch 15/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1315 - accuracy: 0.9483\n",
            "Epoch 00015: val_accuracy did not improve from 0.83600\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1389 - accuracy: 0.9459 - val_loss: 0.5209 - val_accuracy: 0.8320\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.8320\n",
            "using 2 classes\n",
            "Model: \"model_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 40, 100, 3)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 38, 98, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 38, 98, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 38, 98, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_29 (Flatten)         (None, 119168)            0         \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 256)               30507264  \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 30,524,866\n",
            "Trainable params: 30,524,802\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 10.9003 - accuracy: 0.5146\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.62400, saving model to 2D/F.hdf5\n",
            "32/32 [==============================] - 6s 199ms/step - loss: 10.4367 - accuracy: 0.5145 - val_loss: 0.9706 - val_accuracy: 0.6240\n",
            "Epoch 2/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 1.1166 - accuracy: 0.7467\n",
            "Epoch 00002: val_accuracy did not improve from 0.62400\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.0334 - accuracy: 0.7508 - val_loss: 0.8564 - val_accuracy: 0.6120\n",
            "Epoch 3/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.2991 - accuracy: 0.8707\n",
            "Epoch 00003: val_accuracy improved from 0.62400 to 0.79200, saving model to 2D/F.hdf5\n",
            "32/32 [==============================] - 8s 245ms/step - loss: 0.2957 - accuracy: 0.8739 - val_loss: 0.4575 - val_accuracy: 0.7920\n",
            "Epoch 4/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.2440 - accuracy: 0.8924\n",
            "Epoch 00004: val_accuracy did not improve from 0.79200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.2376 - accuracy: 0.8959 - val_loss: 0.6104 - val_accuracy: 0.7040\n",
            "Epoch 5/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.1522 - accuracy: 0.9456\n",
            "Epoch 00005: val_accuracy did not improve from 0.79200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1505 - accuracy: 0.9429 - val_loss: 0.6572 - val_accuracy: 0.7360\n",
            "Epoch 6/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0957 - accuracy: 0.9612\n",
            "Epoch 00006: val_accuracy did not improve from 0.79200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0986 - accuracy: 0.9590 - val_loss: 0.5565 - val_accuracy: 0.7840\n",
            "Epoch 7/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0902 - accuracy: 0.9664\n",
            "Epoch 00007: val_accuracy improved from 0.79200 to 0.79600, saving model to 2D/F.hdf5\n",
            "32/32 [==============================] - 10s 307ms/step - loss: 0.0855 - accuracy: 0.9670 - val_loss: 0.4904 - val_accuracy: 0.7960\n",
            "Epoch 8/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0505 - accuracy: 0.9806\n",
            "Epoch 00008: val_accuracy improved from 0.79600 to 0.80800, saving model to 2D/F.hdf5\n",
            "32/32 [==============================] - 8s 262ms/step - loss: 0.0488 - accuracy: 0.9810 - val_loss: 0.5404 - val_accuracy: 0.8080\n",
            "Epoch 9/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0392 - accuracy: 0.9871\n",
            "Epoch 00009: val_accuracy did not improve from 0.80800\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0388 - accuracy: 0.9880 - val_loss: 0.9082 - val_accuracy: 0.7640\n",
            "Epoch 10/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0409 - accuracy: 0.9860\n",
            "Epoch 00010: val_accuracy did not improve from 0.80800\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0516 - accuracy: 0.9850 - val_loss: 0.6566 - val_accuracy: 0.7800\n",
            "Epoch 11/15\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.0753 - accuracy: 0.9736\n",
            "Epoch 00011: val_accuracy did not improve from 0.80800\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0746 - accuracy: 0.9730 - val_loss: 1.2553 - val_accuracy: 0.6480\n",
            "Epoch 12/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1302 - accuracy: 0.9397\n",
            "Epoch 00012: val_accuracy improved from 0.80800 to 0.87200, saving model to 2D/F.hdf5\n",
            "32/32 [==============================] - 7s 226ms/step - loss: 0.1238 - accuracy: 0.9409 - val_loss: 0.4389 - val_accuracy: 0.8720\n",
            "Epoch 13/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0441 - accuracy: 0.9861\n",
            "Epoch 00013: val_accuracy did not improve from 0.87200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0413 - accuracy: 0.9860 - val_loss: 1.6675 - val_accuracy: 0.6840\n",
            "Epoch 14/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0781 - accuracy: 0.9643\n",
            "Epoch 00014: val_accuracy did not improve from 0.87200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0748 - accuracy: 0.9660 - val_loss: 0.5455 - val_accuracy: 0.8320\n",
            "Epoch 15/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0221 - accuracy: 0.9935\n",
            "Epoch 00015: val_accuracy did not improve from 0.87200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.6111 - val_accuracy: 0.8000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRr96Q17u2Sx",
        "colab_type": "code",
        "outputId": "5b497622-7220-4448-df72-1fa5a63acfb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "labels=[]\n",
        "at2=[]\n",
        "lt2=[]\n",
        "av2=[]\n",
        "lv2=[]\n",
        "t2d=[]\n",
        "for key in models2D:\n",
        "    labels.append(key)\n",
        "    j = models2D[key]['acc']['val_accuracy'].index(max(models2D[key]['acc']['val_accuracy']))\n",
        "    at2.append(models2D[key]['acc']['accuracy'][j])\n",
        "    lt2.append(models2D[key]['acc']['loss'][j])\n",
        "    av2.append(models2D[key]['acc']['val_accuracy'][j])\n",
        "    lv2.append(models2D[key]['acc']['val_loss'][j])\n",
        "    t2d.append(models2D[key]['t'])\n",
        "\n",
        "barplot_model(labels,at2,av2)   \n",
        "barplot_model(labels,lt2,lv2,ylabel='Loss',title='Loss obtained in each architecture',\n",
        "              lab1='Loss train',lab2='Loss test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O5sSs_8-RFE",
        "colab_type": "text"
      },
      "source": [
        "The execution time of the training of each model is logged."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCd40ijJ2fNh",
        "colab_type": "code",
        "outputId": "80fd26b3-f3e6-4331-c459-a196877e4376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(labels,t2d)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdgAAAE/CAYAAADlmNKjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAQm0lEQVR4nO3de4yld13H8c/XLiCXaMEdau0Wp2rFVBSpkwriBanRYolbk4a0MbpqzcYICkKEBRP7l7FEI0JUzEorC8EWgpg2tqJNweCN6pZ7qchaCt2m7Q5X75fi1z/mWTtdtm47Z349c3Zer2Qz57mcc755MrvvfZ5z5kx1dwCAzfVl8x4AAE5GAgsAAwgsAAwgsAAwgMACwAACCwAD7Jj3AEmyc+fOXl5envcYAPCw3HLLLZ/u7qXjbdsSgV1eXs7BgwfnPQYAPCxV9ckH2+YSMQAMILAAMIDAAsAAAgsAAwgsAAwgsAAwgMACwAACCwADCCwADHDCwFbVVVV1pKo+cpxtL6uqrqqd03JV1euq6lBVfaiqzh0xNABsdQ/lDPaNSS44dmVVnZnkB5J8at3q5yU5e/qzN8nrZx8RABbPCQPb3e9J8tnjbHpNkpcn6XXrdid5U695b5JTq+r0TZkUABbIhj7sv6p2J7mruz9YVes3nZHkznXLh6d1dx/nMfZm7Sw3T3nKUzYyBg/R8r7r5z3CEHdcceG8RwB4UA/7TU5V9bgkr0ryy7M8cXfv7+6V7l5ZWjrub/oBgIW1kTPYr09yVpKjZ6+7kryvqs5LcleSM9ftu2taBwDbysM+g+3uD3f3k7t7ubuXs3YZ+NzuvifJdUl+fHo38TOTfKG7v+TyMACc7B7Kj+lcneRvkjy1qg5X1WX/z+43JLk9yaEkv5fkZzdlSgBYMCe8RNzdl55g+/K6253khbOPBQCLzSc5AcAAAgsAAwgsAAwgsAAwgMACwAACCwADCCwADCCwADCAwALAAAILAAMILAAMILAAMIDAAsAAAgsAAwgsAAwgsAAwgMACwAACCwADCCwADCCwADCAwALAAAILAAMILAAMILAAMIDAAsAAAgsAAwgsAAwgsAAwgMACwAACCwADnDCwVXVVVR2pqo+sW/drVfX3VfWhqvqjqjp13bZXVtWhqvpYVf3gqMEBYCt7KGewb0xywTHrbkzytO7+1iT/kOSVSVJV5yS5JMk3T/f5nao6ZdOmBYAFccLAdvd7knz2mHV/1t33TYvvTbJrur07yTXd/Z/d/Ykkh5Kct4nzAsBC2IzXYH8qyZ9Mt89Icue6bYendV+iqvZW1cGqOri6uroJYwDA1jFTYKvql5Lcl+QtD/e+3b2/u1e6e2VpaWmWMQBgy9mx0TtW1U8keX6S87u7p9V3JTlz3W67pnUAsK1s6Ay2qi5I8vIkP9zd/7Zu03VJLqmqx1TVWUnOTvK3s48JAIvlhGewVXV1kuck2VlVh5NcnrV3DT8myY1VlSTv7e6f6e5bq+ptST6atUvHL+zuL44aHgC2qhMGtrsvPc7qK/+f/X8lya/MMhQALDqf5AQAAwgsAAwgsAAwgMACwAACCwADCCwADCCwADCAwALAAAILAAMILAAMILAAMIDAAsAAAgsAAwgsAAwgsAAwgMACwAACCwADCCwADCCwADCAwALAAAILAAMILAAMILAAMIDAAsAAAgsAAwgsAAwgsAAwgMACwAACCwADCCwADHDCwFbVVVV1pKo+sm7dk6rqxqr6+PT1idP6qqrXVdWhqvpQVZ07cngA2KoeyhnsG5NccMy6fUlu6u6zk9w0LSfJ85KcPf3Zm+T1mzMmACyWEwa2u9+T5LPHrN6d5MB0+0CSi9atf1OveW+SU6vq9M0aFgAWxUZfgz2tu++ebt+T5LTp9hlJ7ly33+Fp3Zeoqr1VdbCqDq6urm5wDADYmmZ+k1N3d5LewP32d/dKd68sLS3NOgYAbCkbDey9Ry/9Tl+PTOvvSnLmuv12TesAYFvZaGCvS7Jnur0nybXr1v/49G7iZyb5wrpLyQCwbew40Q5VdXWS5yTZWVWHk1ye5Iokb6uqy5J8MskLpt1vSPJDSQ4l+bckPzlgZgDY8k4Y2O6+9EE2nX+cfTvJC2cdCgAWnU9yAoABBBYABhBYABhAYAFgAIEFgAEEFgAGEFgAGEBgAWAAgQWAAQQWAAYQWAAYQGABYACBBYABTvjbdOBksrzv+nmPMMQdV1w47xGAYziDBYABBBYABhBYABhAYAFgAIEFgAEEFgAGEFgAGEBgAWAAgQWAAQQWAAYQWAAYQGABYACBBYABBBYABhBYABhAYAFggJkCW1W/UFW3VtVHqurqqvryqjqrqm6uqkNV9daqevRmDQsAi2LDga2qM5L8fJKV7n5aklOSXJLk1Ule093fkORzSS7bjEEBYJHMeol4R5LHVtWOJI9LcneS5yZ5+7T9QJKLZnwOAFg4Gw5sd9+V5NeTfCprYf1CkluSfL6775t2O5zkjFmHBIBFM8sl4icm2Z3krCRfk+TxSS54GPffW1UHq+rg6urqRscAgC1plkvE35/kE9292t3/neQdSZ6d5NTpknGS7Epy1/Hu3N37u3ulu1eWlpZmGAMAtp5ZAvupJM+sqsdVVSU5P8lHk7w7ycXTPnuSXDvbiACweGZ5DfbmrL2Z6X1JPjw91v4kr0jy0qo6lOSrkly5CXMCwELZceJdHlx3X57k8mNW357kvFkeFwAWnU9yAoABBBYABhBYABhAYAFgAIEFgAEEFgAGEFgAGEBgAWAAgQWAAQQWAAYQWAAYYKbPIgYW2/K+6+c9whB3XHHhvEcAZ7AAMILAAsAAAgsAAwgsAAwgsAAwgMACwAACCwADCCwADCCwADCAwALAAAILAAMILAAMILAAMIDAAsAAAgsAAwgsAAwgsAAwgMACwAAzBbaqTq2qt1fV31fVbVX1rKp6UlXdWFUfn74+cbOGBYBFMesZ7GuTvLO7vynJ05PclmRfkpu6++wkN03LALCtbDiwVfWVSb4nyZVJ0t3/1d2fT7I7yYFptwNJLpp1SABYNLOcwZ6VZDXJ71fV+6vqDVX1+CSndffd0z73JDlt1iEBYNHMEtgdSc5N8vrufkaSf80xl4O7u5P08e5cVXur6mBVHVxdXZ1hDADYemYJ7OEkh7v75mn57VkL7r1VdXqSTF+PHO/O3b2/u1e6e2VpaWmGMQBg69lwYLv7niR3VtVTp1XnJ/lokuuS7JnW7Uly7UwTAsAC2jHj/X8uyVuq6tFJbk/yk1mL9tuq6rIkn0zyghmfAwAWzkyB7e4PJFk5zqbzZ3lcAFh0PskJAAYQWAAYQGABYACBBYABBBYABpj1x3S2pOV91897hCHuuOLCeY8AwEPkDBYABhBYABhAYAFgAIEFgAEEFgAGEFgAGEBgAWAAgQWAAQQWAAYQWAAYQGABYACBBYABBBYABhBYABhAYAFgAIEFgAEEFgAGEFgAGEBgAWAAgQWAAXbMewAAtp7lfdfPe4Rh7rjiwkfkeZzBAsAAAgsAAwgsAAwwc2Cr6pSqen9V/fG0fFZV3VxVh6rqrVX16NnHBIDFshlnsC9Octu65VcneU13f0OSzyW5bBOeAwAWykyBrapdSS5M8oZpuZI8N8nbp10OJLlolucAgEU06xnsbyZ5eZL/mZa/Ksnnu/u+aflwkjNmfA4AWDgbDmxVPT/Jke6+ZYP331tVB6vq4Orq6kbHAIAtaZYz2Gcn+eGquiPJNVm7NPzaJKdW1dEPsNiV5K7j3bm793f3SnevLC0tzTAGAGw9Gw5sd7+yu3d193KSS5K8q7t/NMm7k1w87bYnybUzTwkAC2bEz8G+IslLq+pQ1l6TvXLAcwDAlrYpn0Xc3X+e5M+n27cnOW8zHhcAFpVPcgKAAQQWAAYQWAAYwO+DBZicrL8D9ZH6/ac8kDNYABhAYAFgAIEFgAEEFgAGEFgAGEBgAWAAgQWAAQQWAAYQWAAYQGABYACBBYABBBYABhBYABhAYAFgAIEFgAEEFgAGEFgAGEBgAWAAgQWAAQQWAAYQWAAYQGABYACBBYABBBYABhBYABhAYAFggA0HtqrOrKp3V9VHq+rWqnrxtP5JVXVjVX18+vrEzRsXABbDLGew9yV5WXefk+SZSV5YVeck2Zfkpu4+O8lN0zIAbCsbDmx3393d75tu/3OS25KckWR3kgPTbgeSXDTrkACwaDblNdiqWk7yjCQ3Jzmtu++eNt2T5LTNeA4AWCQzB7aqnpDkD5O8pLv/af227u4k/SD321tVB6vq4Orq6qxjAMCWMlNgq+pRWYvrW7r7HdPqe6vq9Gn76UmOHO++3b2/u1e6e2VpaWmWMQBgy5nlXcSV5Mokt3X3b6zbdF2SPdPtPUmu3fh4ALCYdsxw32cn+bEkH66qD0zrXpXkiiRvq6rLknwyyQtmGxEAFs+GA9vdf5mkHmTz+Rt9XAA4GfgkJwAYQGABYACBBYABBBYABhBYABhAYAFgAIEFgAEEFgAGEFgAGEBgAWAAgQWAAQQWAAYQWAAYQGABYACBBYABBBYABhBYABhAYAFgAIEFgAEEFgAGEFgAGEBgAWAAgQWAAQQWAAYQWAAYQGABYACBBYABBBYABhBYABhAYAFggGGBraoLqupjVXWoqvaNeh4A2IqGBLaqTkny20mel+ScJJdW1TkjngsAtqJRZ7DnJTnU3bd3938luSbJ7kHPBQBbzqjAnpHkznXLh6d1ALAtVHdv/oNWXZzkgu7+6Wn5x5J8R3e/aN0+e5PsnRafmuRjmz7II2Nnkk/Pe4gtxPG4n2PxQI7HAzke91vkY/G13b10vA07Bj3hXUnOXLe8a1r3f7p7f5L9g57/EVNVB7t7Zd5zbBWOx/0ciwdyPB7I8bjfyXosRl0i/rskZ1fVWVX16CSXJLlu0HMBwJYz5Ay2u++rqhcl+dMkpyS5qrtvHfFcALAVjbpEnO6+IckNox5/C1n4y9ybzPG4n2PxQI7HAzke9zspj8WQNzkBwHbnoxIBYACBnUFVXVRVXVXfNO9Z5qmqvlhVH6iqD1bV+6rqO+c90zxV1VdX1TVV9Y9VdUtV3VBV3zjvueZh3ffGrdP3x8uqalv/u7PumBz9s60/SvY4x2N53jNtFpeIZ1BVb03yNUne1d2Xz3ueeamqf+nuJ0y3fzDJq7r7e+c81lxUVSX56yQHuvt3p3VPT/IV3f0Xcx1uDo753nhykj9I8lf+vqwdE07u47Gt/yc5i6p6QpLvSnJZ1n4MiTVfkeRz8x5ijr4vyX8fjWuSdPcHt2Ncj9XdR7L24TIvmv4jAie1Ye8i3gZ2J3lnd/9DVX2mqr69u2+Z91Bz8tiq+kCSL09yepLnznmeeXpaku36fXBC3X379MtAnpzk3nnPMydH/74c9avd/da5TTN/64/HJ7r7R+Y6zSYS2I27NMlrp9vXTMvb9R/Wf+/ub0uSqnpWkjdV1dPa6w9wPP/394UkJ/HxENgNqKonZe0s7VuqqrP2YRpdVb+43aPS3X9TVTuTLCU5Mu955uDWJBfPe4itqqq+LskXsz2/N9hmvAa7MRcneXN3f213L3f3mUk+keS75zzX3E3vqD4lyWfmPcucvCvJY6ZfZpEkqapvrSrfG1VLSX43yW9t9/+Isj04g92YS5O8+ph1fzitf88jP87crX8NpZLs6e4vznOgeenurqofSfKbVfWKJP+R5I4kL5nrYPNz9HvjUUnuS/LmJL8x35Hm7tjXYN/Z3dv6R3VOVn5MBwAGcIkYAAYQWAAYQGABYACBBYABBBYABhBYABhAYAFgAIEFgAH+FyM4lBccBQGSAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibWrkv1o9keE",
        "colab_type": "text"
      },
      "source": [
        "# **1D convolution over raw audio signal**\n",
        "\n",
        "The amount of neurons of the last 2 fully-connected layers is configurable. Three different values are tested in this exercise. Batch normalization is an additional parameter that could be selected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__T5aKtquLi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_conv_model_1D(num_classes,bn=False,neurons=[256,64],compile=True):\n",
        "    print(\"using\",num_classes,\"classes\")\n",
        "    inputs = tf.keras.Input(shape=(48000,1), name=\"input_1\")\n",
        "    layers = tf.keras.layers.Conv1D(40,1800, strides = 240)(inputs)\n",
        "    if bn:\n",
        "        layers = tf.keras.layers.BatchNormalization()(layers)\n",
        "    layers = tf.keras.layers.Activation('relu')(layers)\n",
        "    layers = tf.keras.layers.Flatten()(layers)\n",
        "    layers = tf.keras.layers.Dense(neurons[0], activation=tf.nn.relu)(layers)\n",
        "    layers = tf.keras.layers.Dense(neurons[1], activation=tf.nn.relu)(layers)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    predictions = tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax, name=\"output_1\")(layers)\n",
        "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
        "    if compile:\n",
        "        model.compile(optimizer='adam',\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "    \n",
        "def train1D(model, batch_size, epochs, model_name=\"\"):\n",
        "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"1D/logs/\"+model_name+\"_\"+\"{}\".format(time()))\n",
        "    model.reset_states()\n",
        "    checkpoint = ModelCheckpoint(\"1D/\"+model_name+\".hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1)\n",
        "    history = model.fit(x_train, y_train, epochs=epochs, callbacks=[tensorboard, checkpoint],\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(x_test, y_test))\n",
        "    metrics = model.evaluate(x_test, y_test)\n",
        "    return {k:v for k,v in zip (model.metrics_names, metrics)}, history.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8w8F8cB9wau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data1D.pkl','rb') as g: \n",
        "    y_train_gender, x_train_gender = pickle.load(g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL9wM-NP_ONs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models1D = {'A':{'bn':False,'layers':[1024,256],'acc':0,'t':0},'B':{'bn':True,'layers':[1024,256],'acc':0,'t':0},\n",
        "          'C':{'bn':False,'layers':[512,128],'acc':0,'t':0},'D':{'bn':True,'layers':[512,128],'acc':0,'t':0},\n",
        "          'E':{'bn':False,'layers':[256,64],'acc':0,'t':0},'F':{'bn':True,'layers':[256,64],'acc':0,'t':0}}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCYqAmz09vWU",
        "colab_type": "text"
      },
      "source": [
        "An input of the neural network consists in one vector of size 48000. This vector is sampled from a one-second long audio that is taken from the second audio of each file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY694xa7_Qeg",
        "colab_type": "code",
        "outputId": "2a4ca76f-1f33-4f44-d9c0-8f0c961e345b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_train_gender, y_train_gender, test_size=.20,stratify=y_train_gender)\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "print(\"\\ndistribution of train classes\")\n",
        "print(pd.Series(y_train).value_counts())\n",
        "print(\"\\ndistribution of test classes\")\n",
        "print(pd.Series(y_test).value_counts())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1005, 48000, 1) (1005,) (252, 48000, 1) (252,)\n",
            "\n",
            "distribution of train classes\n",
            "1    524\n",
            "0    481\n",
            "dtype: int64\n",
            "\n",
            "distribution of test classes\n",
            "1    131\n",
            "0    121\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS-U3azg_UzM",
        "colab_type": "code",
        "outputId": "3ab43455-45b1-455b-d115-fc8a0be748b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "for key in models1D:\n",
        "    start_time = time()\n",
        "    modelY = get_conv_model_1D(2,models1D[key]['bn'],models1D[key]['layers'])\n",
        "    print(modelY.summary())\n",
        "    results, models1D[key]['acc'] = train1D(modelY, batch_size=32, epochs=15, model_name=key)\n",
        "    models1D[key]['t'] = time() - start_time\n",
        "    print(time()-start_time)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using 2 classes\n",
            "Model: \"model_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 48000, 1)]        0         \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 193, 40)           72040     \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 193, 40)           0         \n",
            "_________________________________________________________________\n",
            "flatten_30 (Flatten)         (None, 7720)              0         \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 1024)              7906304   \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 8,241,258\n",
            "Trainable params: 8,241,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 794.0205 - accuracy: 0.5156 \n",
            "Epoch 00001: val_accuracy improved from -inf to 0.52778, saving model to 1D/A.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 737.1996 - accuracy: 0.5164 - val_loss: 479.5688 - val_accuracy: 0.5278\n",
            "Epoch 2/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 80.5253 - accuracy: 0.6953\n",
            "Epoch 00002: val_accuracy improved from 0.52778 to 0.67460, saving model to 1D/A.hdf5\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 73.7491 - accuracy: 0.7085 - val_loss: 53.0462 - val_accuracy: 0.6746\n",
            "Epoch 3/15\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 14.3128 - accuracy: 0.7885\n",
            "Epoch 00003: val_accuracy improved from 0.67460 to 0.67857, saving model to 1D/A.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 13.0619 - accuracy: 0.7891 - val_loss: 4.1881 - val_accuracy: 0.6786\n",
            "Epoch 4/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 1.4105 - accuracy: 0.7567\n",
            "Epoch 00004: val_accuracy improved from 0.67857 to 0.73413, saving model to 1D/A.hdf5\n",
            "32/32 [==============================] - 1s 31ms/step - loss: 1.3109 - accuracy: 0.7582 - val_loss: 0.7923 - val_accuracy: 0.7341\n",
            "Epoch 5/15\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.6516 - accuracy: 0.8263\n",
            "Epoch 00005: val_accuracy improved from 0.73413 to 0.76190, saving model to 1D/A.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.6846 - accuracy: 0.8348 - val_loss: 1.0295 - val_accuracy: 0.7619\n",
            "Epoch 6/15\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.3479 - accuracy: 0.8546\n",
            "Epoch 00006: val_accuracy did not improve from 0.76190\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3501 - accuracy: 0.8547 - val_loss: 1.1103 - val_accuracy: 0.7302\n",
            "Epoch 7/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.3477 - accuracy: 0.8534\n",
            "Epoch 00007: val_accuracy did not improve from 0.76190\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3336 - accuracy: 0.8577 - val_loss: 1.0228 - val_accuracy: 0.7579\n",
            "Epoch 8/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.3366 - accuracy: 0.8600\n",
            "Epoch 00008: val_accuracy did not improve from 0.76190\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3277 - accuracy: 0.8597 - val_loss: 1.3243 - val_accuracy: 0.7500\n",
            "Epoch 9/15\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.3707 - accuracy: 0.8606\n",
            "Epoch 00009: val_accuracy did not improve from 0.76190\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3520 - accuracy: 0.8677 - val_loss: 1.1696 - val_accuracy: 0.7421\n",
            "Epoch 10/15\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.2759 - accuracy: 0.8870\n",
            "Epoch 00010: val_accuracy improved from 0.76190 to 0.76984, saving model to 1D/A.hdf5\n",
            "32/32 [==============================] - 1s 37ms/step - loss: 0.2844 - accuracy: 0.8846 - val_loss: 1.3277 - val_accuracy: 0.7698\n",
            "Epoch 11/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.2456 - accuracy: 0.8819\n",
            "Epoch 00011: val_accuracy did not improve from 0.76984\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2545 - accuracy: 0.8806 - val_loss: 1.3358 - val_accuracy: 0.7460\n",
            "Epoch 12/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.2351 - accuracy: 0.8970\n",
            "Epoch 00012: val_accuracy did not improve from 0.76984\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2347 - accuracy: 0.8975 - val_loss: 1.3947 - val_accuracy: 0.7659\n",
            "Epoch 13/15\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.2312 - accuracy: 0.9002\n",
            "Epoch 00013: val_accuracy improved from 0.76984 to 0.78175, saving model to 1D/A.hdf5\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2304 - accuracy: 0.9035 - val_loss: 1.1684 - val_accuracy: 0.7817\n",
            "Epoch 14/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.1940 - accuracy: 0.9219\n",
            "Epoch 00014: val_accuracy did not improve from 0.78175\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2008 - accuracy: 0.9174 - val_loss: 1.4123 - val_accuracy: 0.7579\n",
            "Epoch 15/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.1993 - accuracy: 0.9208\n",
            "Epoch 00015: val_accuracy did not improve from 0.78175\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2148 - accuracy: 0.9164 - val_loss: 1.3352 - val_accuracy: 0.7540\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3352 - accuracy: 0.7540\n",
            "9.38523268699646\n",
            "using 2 classes\n",
            "Model: \"model_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 48000, 1)]        0         \n",
            "_________________________________________________________________\n",
            "conv1d_19 (Conv1D)           (None, 193, 40)           72040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 193, 40)           160       \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 193, 40)           0         \n",
            "_________________________________________________________________\n",
            "flatten_31 (Flatten)         (None, 7720)              0         \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 1024)              7906304   \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 8,241,418\n",
            "Trainable params: 8,241,338\n",
            "Non-trainable params: 80\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 1.3836 - accuracy: 0.5054\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.62698, saving model to 1D/B.hdf5\n",
            "32/32 [==============================] - 1s 43ms/step - loss: 1.3281 - accuracy: 0.5174 - val_loss: 0.8017 - val_accuracy: 0.6270\n",
            "Epoch 2/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.5508 - accuracy: 0.7060\n",
            "Epoch 00002: val_accuracy improved from 0.62698 to 0.77778, saving model to 1D/B.hdf5\n",
            "32/32 [==============================] - 4s 131ms/step - loss: 0.5333 - accuracy: 0.7224 - val_loss: 0.7618 - val_accuracy: 0.7778\n",
            "Epoch 3/15\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.4102 - accuracy: 0.8250\n",
            "Epoch 00003: val_accuracy improved from 0.77778 to 0.78968, saving model to 1D/B.hdf5\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3984 - accuracy: 0.8289 - val_loss: 0.5500 - val_accuracy: 0.7897\n",
            "Epoch 4/15\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.2621 - accuracy: 0.9137\n",
            "Epoch 00004: val_accuracy did not improve from 0.78968\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2869 - accuracy: 0.8955 - val_loss: 0.7678 - val_accuracy: 0.7738\n",
            "Epoch 5/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.2271 - accuracy: 0.9225\n",
            "Epoch 00005: val_accuracy did not improve from 0.78968\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2268 - accuracy: 0.9204 - val_loss: 1.0082 - val_accuracy: 0.7698\n",
            "Epoch 6/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.1476 - accuracy: 0.9549\n",
            "Epoch 00006: val_accuracy did not improve from 0.78968\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1624 - accuracy: 0.9473 - val_loss: 2.3854 - val_accuracy: 0.6865\n",
            "Epoch 7/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.2008 - accuracy: 0.9353\n",
            "Epoch 00007: val_accuracy did not improve from 0.78968\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2054 - accuracy: 0.9313 - val_loss: 0.9430 - val_accuracy: 0.7500\n",
            "Epoch 8/15\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.1566 - accuracy: 0.9475\n",
            "Epoch 00008: val_accuracy did not improve from 0.78968\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1641 - accuracy: 0.9473 - val_loss: 1.4469 - val_accuracy: 0.7460\n",
            "Epoch 9/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.2100 - accuracy: 0.9421\n",
            "Epoch 00009: val_accuracy did not improve from 0.78968\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2252 - accuracy: 0.9423 - val_loss: 1.0794 - val_accuracy: 0.7619\n",
            "Epoch 10/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.1845 - accuracy: 0.9464\n",
            "Epoch 00010: val_accuracy did not improve from 0.78968\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1879 - accuracy: 0.9453 - val_loss: 1.5292 - val_accuracy: 0.7381\n",
            "Epoch 11/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.2003 - accuracy: 0.9387\n",
            "Epoch 00011: val_accuracy did not improve from 0.78968\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1945 - accuracy: 0.9413 - val_loss: 1.5292 - val_accuracy: 0.7143\n",
            "Epoch 12/15\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.1406 - accuracy: 0.9519\n",
            "Epoch 00012: val_accuracy did not improve from 0.78968\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1320 - accuracy: 0.9562 - val_loss: 1.7104 - val_accuracy: 0.7460\n",
            "Epoch 13/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.1104 - accuracy: 0.9609\n",
            "Epoch 00013: val_accuracy did not improve from 0.78968\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1231 - accuracy: 0.9602 - val_loss: 1.4416 - val_accuracy: 0.7381\n",
            "Epoch 14/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0993 - accuracy: 0.9643\n",
            "Epoch 00014: val_accuracy did not improve from 0.78968\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0984 - accuracy: 0.9662 - val_loss: 1.5158 - val_accuracy: 0.7262\n",
            "Epoch 15/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.1018 - accuracy: 0.9810\n",
            "Epoch 00015: val_accuracy did not improve from 0.78968\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0937 - accuracy: 0.9821 - val_loss: 1.5415 - val_accuracy: 0.7262\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5415 - accuracy: 0.7262\n",
            "12.572401762008667\n",
            "using 2 classes\n",
            "Model: \"model_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 48000, 1)]        0         \n",
            "_________________________________________________________________\n",
            "conv1d_20 (Conv1D)           (None, 193, 40)           72040     \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 193, 40)           0         \n",
            "_________________________________________________________________\n",
            "flatten_32 (Flatten)         (None, 7720)              0         \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 512)               3953152   \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 4,091,114\n",
            "Trainable params: 4,091,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/15\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 941.0807 - accuracy: 0.5170 \n",
            "Epoch 00001: val_accuracy improved from -inf to 0.54762, saving model to 1D/C.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 723.6976 - accuracy: 0.5333 - val_loss: 304.3188 - val_accuracy: 0.5476\n",
            "Epoch 2/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 171.1947 - accuracy: 0.5948\n",
            "Epoch 00002: val_accuracy improved from 0.54762 to 0.59524, saving model to 1D/C.hdf5\n",
            "32/32 [==============================] - 1s 44ms/step - loss: 167.4867 - accuracy: 0.5970 - val_loss: 76.8388 - val_accuracy: 0.5952\n",
            "Epoch 3/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 29.4049 - accuracy: 0.7198\n",
            "Epoch 00003: val_accuracy improved from 0.59524 to 0.65873, saving model to 1D/C.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 28.6413 - accuracy: 0.7264 - val_loss: 31.1848 - val_accuracy: 0.6587\n",
            "Epoch 4/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 9.6384 - accuracy: 0.7400 \n",
            "Epoch 00004: val_accuracy did not improve from 0.65873\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.7611 - accuracy: 0.7433 - val_loss: 7.1407 - val_accuracy: 0.5476\n",
            "Epoch 5/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 2.4062 - accuracy: 0.7833\n",
            "Epoch 00005: val_accuracy did not improve from 0.65873\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.2700 - accuracy: 0.7871 - val_loss: 9.7891 - val_accuracy: 0.6468\n",
            "Epoch 6/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 1.1413 - accuracy: 0.7899\n",
            "Epoch 00006: val_accuracy improved from 0.65873 to 0.67063, saving model to 1D/C.hdf5\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 1.1446 - accuracy: 0.7940 - val_loss: 3.7600 - val_accuracy: 0.6706\n",
            "Epoch 7/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.6694 - accuracy: 0.8052\n",
            "Epoch 00007: val_accuracy did not improve from 0.67063\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6993 - accuracy: 0.8030 - val_loss: 2.8449 - val_accuracy: 0.6429\n",
            "Epoch 8/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.7011 - accuracy: 0.8200\n",
            "Epoch 00008: val_accuracy did not improve from 0.67063\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6718 - accuracy: 0.8169 - val_loss: 3.7303 - val_accuracy: 0.5992\n",
            "Epoch 9/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.5225 - accuracy: 0.8367\n",
            "Epoch 00009: val_accuracy improved from 0.67063 to 0.70635, saving model to 1D/C.hdf5\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.5111 - accuracy: 0.8378 - val_loss: 6.6966 - val_accuracy: 0.7063\n",
            "Epoch 10/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 1.3522 - accuracy: 0.8531\n",
            "Epoch 00010: val_accuracy did not improve from 0.70635\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.4032 - accuracy: 0.8537 - val_loss: 3.8839 - val_accuracy: 0.6786\n",
            "Epoch 11/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.4217 - accuracy: 0.8469\n",
            "Epoch 00011: val_accuracy did not improve from 0.70635\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.8488 - val_loss: 5.1139 - val_accuracy: 0.6429\n",
            "Epoch 12/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.7048 - accuracy: 0.8292\n",
            "Epoch 00012: val_accuracy did not improve from 0.70635\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6783 - accuracy: 0.8199 - val_loss: 1.9303 - val_accuracy: 0.6032\n",
            "Epoch 13/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.3746 - accuracy: 0.8387\n",
            "Epoch 00013: val_accuracy did not improve from 0.70635\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.3814 - accuracy: 0.8388 - val_loss: 1.5652 - val_accuracy: 0.6984\n",
            "Epoch 14/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.3419 - accuracy: 0.8615\n",
            "Epoch 00014: val_accuracy improved from 0.70635 to 0.72222, saving model to 1D/C.hdf5\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.3438 - accuracy: 0.8597 - val_loss: 1.6156 - val_accuracy: 0.7222\n",
            "Epoch 15/15\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.4044 - accuracy: 0.8786\n",
            "Epoch 00015: val_accuracy improved from 0.72222 to 0.73016, saving model to 1D/C.hdf5\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.3727 - accuracy: 0.8836 - val_loss: 1.7230 - val_accuracy: 0.7302\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7230 - accuracy: 0.7302\n",
            "7.411467790603638\n",
            "using 2 classes\n",
            "Model: \"model_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 48000, 1)]        0         \n",
            "_________________________________________________________________\n",
            "conv1d_21 (Conv1D)           (None, 193, 40)           72040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 193, 40)           160       \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 193, 40)           0         \n",
            "_________________________________________________________________\n",
            "flatten_33 (Flatten)         (None, 7720)              0         \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 512)               3953152   \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 4,091,274\n",
            "Trainable params: 4,091,194\n",
            "Non-trainable params: 80\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 1.0781 - accuracy: 0.5097\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.61905, saving model to 1D/D.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.0560 - accuracy: 0.4995 - val_loss: 0.6650 - val_accuracy: 0.6190\n",
            "Epoch 2/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.6186 - accuracy: 0.6703\n",
            "Epoch 00002: val_accuracy improved from 0.61905 to 0.67063, saving model to 1D/D.hdf5\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.6044 - accuracy: 0.6806 - val_loss: 0.7708 - val_accuracy: 0.6706\n",
            "Epoch 3/15\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.5225 - accuracy: 0.7613\n",
            "Epoch 00003: val_accuracy improved from 0.67063 to 0.72619, saving model to 1D/D.hdf5\n",
            "32/32 [==============================] - 1s 46ms/step - loss: 0.4908 - accuracy: 0.7761 - val_loss: 0.6775 - val_accuracy: 0.7262\n",
            "Epoch 4/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.3386 - accuracy: 0.8669\n",
            "Epoch 00004: val_accuracy improved from 0.72619 to 0.74603, saving model to 1D/D.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.3394 - accuracy: 0.8597 - val_loss: 0.5642 - val_accuracy: 0.7460\n",
            "Epoch 5/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.2524 - accuracy: 0.9029\n",
            "Epoch 00005: val_accuracy improved from 0.74603 to 0.76190, saving model to 1D/D.hdf5\n",
            "32/32 [==============================] - 1s 45ms/step - loss: 0.2505 - accuracy: 0.9045 - val_loss: 0.7957 - val_accuracy: 0.7619\n",
            "Epoch 6/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.2351 - accuracy: 0.9214\n",
            "Epoch 00006: val_accuracy did not improve from 0.76190\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2393 - accuracy: 0.9204 - val_loss: 0.8162 - val_accuracy: 0.7500\n",
            "Epoch 7/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1929 - accuracy: 0.9278\n",
            "Epoch 00007: val_accuracy did not improve from 0.76190\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1984 - accuracy: 0.9284 - val_loss: 1.6736 - val_accuracy: 0.7421\n",
            "Epoch 8/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1906 - accuracy: 0.9355\n",
            "Epoch 00008: val_accuracy did not improve from 0.76190\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1863 - accuracy: 0.9363 - val_loss: 1.4433 - val_accuracy: 0.7341\n",
            "Epoch 9/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.3882 - accuracy: 0.8653\n",
            "Epoch 00009: val_accuracy did not improve from 0.76190\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.3726 - accuracy: 0.8706 - val_loss: 0.6708 - val_accuracy: 0.7500\n",
            "Epoch 10/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.2228 - accuracy: 0.9325\n",
            "Epoch 00010: val_accuracy improved from 0.76190 to 0.77381, saving model to 1D/D.hdf5\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.2213 - accuracy: 0.9323 - val_loss: 0.9155 - val_accuracy: 0.7738\n",
            "Epoch 11/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.1226 - accuracy: 0.9641\n",
            "Epoch 00011: val_accuracy did not improve from 0.77381\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1301 - accuracy: 0.9612 - val_loss: 1.1465 - val_accuracy: 0.7659\n",
            "Epoch 12/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0703 - accuracy: 0.9766\n",
            "Epoch 00012: val_accuracy did not improve from 0.77381\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0704 - accuracy: 0.9751 - val_loss: 1.6417 - val_accuracy: 0.7421\n",
            "Epoch 13/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0697 - accuracy: 0.9760\n",
            "Epoch 00013: val_accuracy did not improve from 0.77381\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0693 - accuracy: 0.9761 - val_loss: 1.9493 - val_accuracy: 0.7500\n",
            "Epoch 14/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.1086 - accuracy: 0.9688\n",
            "Epoch 00014: val_accuracy did not improve from 0.77381\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1507 - accuracy: 0.9622 - val_loss: 1.3984 - val_accuracy: 0.7500\n",
            "Epoch 15/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.2845 - accuracy: 0.9294\n",
            "Epoch 00015: val_accuracy improved from 0.77381 to 0.77778, saving model to 1D/D.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.2784 - accuracy: 0.9303 - val_loss: 1.1784 - val_accuracy: 0.7778\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1784 - accuracy: 0.7778\n",
            "7.788793325424194\n",
            "using 2 classes\n",
            "Model: \"model_34\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 48000, 1)]        0         \n",
            "_________________________________________________________________\n",
            "conv1d_22 (Conv1D)           (None, 193, 40)           72040     \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 193, 40)           0         \n",
            "_________________________________________________________________\n",
            "flatten_34 (Flatten)         (None, 7720)              0         \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 256)               1976576   \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,065,194\n",
            "Trainable params: 2,065,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/15\n",
            "32/32 [==============================] - ETA: 0s - loss: 546.7028 - accuracy: 0.5463\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.50397, saving model to 1D/E.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 546.7028 - accuracy: 0.5463 - val_loss: 149.3785 - val_accuracy: 0.5040\n",
            "Epoch 2/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 91.3647 - accuracy: 0.6510 \n",
            "Epoch 00002: val_accuracy improved from 0.50397 to 0.54762, saving model to 1D/E.hdf5\n",
            "32/32 [==============================] - 1s 32ms/step - loss: 93.7846 - accuracy: 0.6438 - val_loss: 54.9290 - val_accuracy: 0.5476\n",
            "Epoch 3/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 36.5039 - accuracy: 0.6606\n",
            "Epoch 00003: val_accuracy did not improve from 0.54762\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 33.7978 - accuracy: 0.6587 - val_loss: 14.4672 - val_accuracy: 0.5357\n",
            "Epoch 4/15\n",
            "32/32 [==============================] - ETA: 0s - loss: 5.4027 - accuracy: 0.6179\n",
            "Epoch 00004: val_accuracy did not improve from 0.54762\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.4027 - accuracy: 0.6179 - val_loss: 4.1383 - val_accuracy: 0.5079\n",
            "Epoch 5/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 1.8741 - accuracy: 0.6028\n",
            "Epoch 00005: val_accuracy improved from 0.54762 to 0.59921, saving model to 1D/E.hdf5\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.8364 - accuracy: 0.6040 - val_loss: 3.1963 - val_accuracy: 0.5992\n",
            "Epoch 6/15\n",
            "32/32 [==============================] - ETA: 0s - loss: 1.2732 - accuracy: 0.6557\n",
            "Epoch 00006: val_accuracy improved from 0.59921 to 0.60714, saving model to 1D/E.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.2732 - accuracy: 0.6557 - val_loss: 2.7238 - val_accuracy: 0.6071\n",
            "Epoch 7/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 1.4090 - accuracy: 0.6678\n",
            "Epoch 00007: val_accuracy improved from 0.60714 to 0.63095, saving model to 1D/E.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.3450 - accuracy: 0.6577 - val_loss: 3.0102 - val_accuracy: 0.6310\n",
            "Epoch 8/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.5647 - accuracy: 0.7299\n",
            "Epoch 00008: val_accuracy improved from 0.63095 to 0.67857, saving model to 1D/E.hdf5\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 0.5533 - accuracy: 0.7393 - val_loss: 2.9281 - val_accuracy: 0.6786\n",
            "Epoch 9/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.4692 - accuracy: 0.8185\n",
            "Epoch 00009: val_accuracy did not improve from 0.67857\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.4672 - accuracy: 0.8189 - val_loss: 2.8817 - val_accuracy: 0.6746\n",
            "Epoch 10/15\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.5289 - accuracy: 0.7801\n",
            "Epoch 00010: val_accuracy improved from 0.67857 to 0.69841, saving model to 1D/E.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5289 - accuracy: 0.7801 - val_loss: 3.0256 - val_accuracy: 0.6984\n",
            "Epoch 11/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.6342 - accuracy: 0.8039\n",
            "Epoch 00011: val_accuracy did not improve from 0.69841\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6123 - accuracy: 0.8030 - val_loss: 3.0704 - val_accuracy: 0.6984\n",
            "Epoch 12/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.5045 - accuracy: 0.7791\n",
            "Epoch 00012: val_accuracy did not improve from 0.69841\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.4931 - accuracy: 0.7811 - val_loss: 1.9364 - val_accuracy: 0.6587\n",
            "Epoch 13/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.4720 - accuracy: 0.7974\n",
            "Epoch 00013: val_accuracy did not improve from 0.69841\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.4707 - accuracy: 0.7990 - val_loss: 1.9476 - val_accuracy: 0.6984\n",
            "Epoch 14/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.5203 - accuracy: 0.8177\n",
            "Epoch 00014: val_accuracy did not improve from 0.69841\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5159 - accuracy: 0.8179 - val_loss: 2.0086 - val_accuracy: 0.6944\n",
            "Epoch 15/15\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.4360 - accuracy: 0.8139\n",
            "Epoch 00015: val_accuracy improved from 0.69841 to 0.70635, saving model to 1D/E.hdf5\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4360 - accuracy: 0.8139 - val_loss: 2.0065 - val_accuracy: 0.7063\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0065 - accuracy: 0.7063\n",
            "6.154165506362915\n",
            "using 2 classes\n",
            "Model: \"model_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 48000, 1)]        0         \n",
            "_________________________________________________________________\n",
            "conv1d_23 (Conv1D)           (None, 193, 40)           72040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 193, 40)           160       \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 193, 40)           0         \n",
            "_________________________________________________________________\n",
            "flatten_35 (Flatten)         (None, 7720)              0         \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 256)               1976576   \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "output_1 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,065,354\n",
            "Trainable params: 2,065,274\n",
            "Non-trainable params: 80\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.8942 - accuracy: 0.5010\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.57937, saving model to 1D/F.hdf5\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 0.8860 - accuracy: 0.5035 - val_loss: 0.6922 - val_accuracy: 0.5794\n",
            "Epoch 2/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.6692 - accuracy: 0.6007\n",
            "Epoch 00002: val_accuracy improved from 0.57937 to 0.61111, saving model to 1D/F.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6771 - accuracy: 0.6030 - val_loss: 0.6993 - val_accuracy: 0.6111\n",
            "Epoch 3/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.5200 - accuracy: 0.7396\n",
            "Epoch 00003: val_accuracy improved from 0.61111 to 0.64683, saving model to 1D/F.hdf5\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 0.5224 - accuracy: 0.7403 - val_loss: 0.6919 - val_accuracy: 0.6468\n",
            "Epoch 4/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8498\n",
            "Epoch 00004: val_accuracy improved from 0.64683 to 0.70635, saving model to 1D/F.hdf5\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.3813 - accuracy: 0.8498 - val_loss: 0.6159 - val_accuracy: 0.7063\n",
            "Epoch 5/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.2710 - accuracy: 0.8958\n",
            "Epoch 00005: val_accuracy improved from 0.70635 to 0.73810, saving model to 1D/F.hdf5\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.2706 - accuracy: 0.8965 - val_loss: 0.9054 - val_accuracy: 0.7381\n",
            "Epoch 6/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.2635 - accuracy: 0.9051\n",
            "Epoch 00006: val_accuracy did not improve from 0.73810\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2693 - accuracy: 0.8965 - val_loss: 0.8757 - val_accuracy: 0.7262\n",
            "Epoch 7/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.3078 - accuracy: 0.8885\n",
            "Epoch 00007: val_accuracy improved from 0.73810 to 0.75000, saving model to 1D/F.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3025 - accuracy: 0.8905 - val_loss: 0.6529 - val_accuracy: 0.7500\n",
            "Epoch 8/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1982 - accuracy: 0.9355\n",
            "Epoch 00008: val_accuracy did not improve from 0.75000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1963 - accuracy: 0.9353 - val_loss: 0.9926 - val_accuracy: 0.7421\n",
            "Epoch 9/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.1452 - accuracy: 0.9542\n",
            "Epoch 00009: val_accuracy did not improve from 0.75000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1409 - accuracy: 0.9562 - val_loss: 1.1997 - val_accuracy: 0.7302\n",
            "Epoch 10/15\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.1172 - accuracy: 0.9583\n",
            "Epoch 00010: val_accuracy did not improve from 0.75000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1339 - accuracy: 0.9532 - val_loss: 1.4184 - val_accuracy: 0.7262\n",
            "Epoch 11/15\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.9264\n",
            "Epoch 00011: val_accuracy did not improve from 0.75000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2752 - accuracy: 0.9274 - val_loss: 1.2173 - val_accuracy: 0.7222\n",
            "Epoch 12/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.1421 - accuracy: 0.9542\n",
            "Epoch 00012: val_accuracy did not improve from 0.75000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1371 - accuracy: 0.9562 - val_loss: 1.3010 - val_accuracy: 0.7222\n",
            "Epoch 13/15\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0687 - accuracy: 0.9817\n",
            "Epoch 00013: val_accuracy did not improve from 0.75000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0706 - accuracy: 0.9791 - val_loss: 1.7333 - val_accuracy: 0.7421\n",
            "Epoch 14/15\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0742 - accuracy: 0.9844\n",
            "Epoch 00014: val_accuracy did not improve from 0.75000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0815 - accuracy: 0.9801 - val_loss: 1.8032 - val_accuracy: 0.7500\n",
            "Epoch 15/15\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0923 - accuracy: 0.9792\n",
            "Epoch 00015: val_accuracy did not improve from 0.75000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0911 - accuracy: 0.9781 - val_loss: 1.7951 - val_accuracy: 0.7183\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7951 - accuracy: 0.7183\n",
            "6.671670913696289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cODL1H2K_Wyz",
        "colab_type": "code",
        "outputId": "dca651e5-a652-4002-d3f8-23bfc017f623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "labels=[]\n",
        "at1=[]\n",
        "lt1=[]\n",
        "av1=[]\n",
        "lv1=[]\n",
        "t1d=[]\n",
        "for key in models1D:\n",
        "    labels.append(key)\n",
        "    i = models1D[key]['acc']['val_accuracy'].index(max(models1D[key]['acc']['val_accuracy']))\n",
        "    at1.append(models1D[key]['acc']['accuracy'][i])\n",
        "    lt1.append(models1D[key]['acc']['loss'][i])\n",
        "    av1.append(models1D[key]['acc']['val_accuracy'][i])\n",
        "    lv1.append(models1D[key]['acc']['val_loss'][i])\n",
        "    t1d.append(models1D[key]['t'])\n",
        "\n",
        "barplot_model(labels,at1,av1)   \n",
        "barplot_model(labels,lt1,lv1,ylabel='Loss',title='Loss obtained in each architecture',\n",
        "              lab1='Loss train',lab2='Loss test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAWGDGg4By-s",
        "colab_type": "code",
        "outputId": "0b1e2bc5-3970-4349-dc75-5e3258f636e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(labels,t1d)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Mxs2T66-ap-",
        "colab_type": "text"
      },
      "source": [
        "A comparison of execution time of equivalent 1D and 2D models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWidqPvB76aF",
        "colab_type": "code",
        "outputId": "a6d5017e-c038-4c1f-fb24-d0bad00693b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "barplot_model(labels,t1d,t2d,ylabel='Execution time',\n",
        "                       title='Training time in each architecture', \n",
        "                  lab1='1D',lab2='2D')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}